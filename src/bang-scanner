#!/usr/bin/env python3

# Binary Analysis Next Generation (BANG!)
#
# This file is part of BANG.
#
# BANG is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License,
# version 3, as published by the Free Software Foundation.
#
# BANG is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public
# License, version 3, along with BANG.  If not, see
# <http://www.gnu.org/licenses/>
#
# Copyright 2018-2021 - Armijn Hemel
# Licensed under the terms of the GNU Affero General Public License
# version 3
# SPDX-License-Identifier: AGPL-3.0-only
#
# Gets a file and unpacks contents using standard functionality in
# Python 3 or some custom code and writes the contents to a temporary
# directory.

import sys
import os
import pathlib
import stat
import shutil
import datetime
import tempfile
import uuid

# import modules needed for multiprocessing
import multiprocessing
import queue

# import some module for collecting statistics and information about
# the run time environment of the tool, plus of runs.
import logging
import platform
import getpass

# import other local files
from bangsignatures import maxsignaturesoffset
from bangscanneroptions import BangScannerOptions
from banglogging import log
import banglogging

from reporter.picklereport import *
from reporter.jsonreport import *
from reporter.humanreadablereport import *

from FileContentsComputer import *
from FileResult import FileResult
from ScanEnvironment import *
from UnpackManager import *
from ScanJob import *


def main(argv):
    options = BangScannerOptions().get()

    # first determine how many bytes should be scanned for known
    # signatures using a sliding window. This should not be set too
    # large for performance reasons and not too low (to avoid a
    # silly window). Ideally this is a few times the value of
    # 'maxsignaturesoffset'
    maxbytes = max(200000, maxsignaturesoffset+1)

    # create a list of all the files that should be scanned
    checkfiles = []
    if os.path.isdir(options.checkpath):
        dirwalk = os.walk(options.checkpath)
        for i in dirwalk:
            for j in i[2]:
                scanfilename = os.path.join(i[0], j)
                if not os.path.exists(scanfilename):
                    continue

                # ... and should be a real file
                if not stat.S_ISREG(os.stat(scanfilename).st_mode):
                    continue

                filesize = os.stat(scanfilename).st_size
                # Don't scan an empty file
                if filesize == 0:
                    continue
                checkfiles.append(scanfilename)
    else:
        checkfiles.append(options.checkpath)

    if not checkfiles:
        print("No files to scan found, exiting", file=sys.stderr)
        sys.exit(1)

    if options.uselogging:
        banglogging.uselogging = True
        # set up logging
        logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')
        banglogger = logging.getLogger()

        # remove the standard log handler, as it will be different
        # per scan directory
        for i in banglogger.handlers:
            banglogger.removeHandler(i)

    unpackers = bangsignatures.get_unpackers()

    # scan each individual file that needs to be scanned in
    # alphabetical sort order (Python default)
    for checkfile in sorted(checkfiles):
        # store a UTC time stamp
        scandate = datetime.datetime.utcnow()

        # create a unique identifier for the scan
        scanuuid = uuid.uuid4()

        # create a directory for the scan
        scandirectory = pathlib.Path(tempfile.mkdtemp(prefix='bang-scan-',
                                                      dir=options.baseunpackdirectory))

        # create an empty file "STARTED" to easily identify
        # active (or crashed) scans.
        startedfile = open(scandirectory / "STARTED", 'wb')
        startedfile.close()

        # now create a directory structure inside the scandirectory:
        # unpack/ -- this is where all the unpacked data will be stored
        # results/ -- this is where files describing the unpacked data
        #             will be stored
        # logs/ -- this is where logs from the scan will be stored
        unpackdirectory = scandirectory / "unpack"
        unpackdirectory.mkdir()

        resultsdirectory = scandirectory / "results"
        resultsdirectory.mkdir()

        if banglogging.uselogging:
            logdirectory = scandirectory / "logs"
            logdirectory.mkdir()

            # create a log file inside the log directory and
            # add it to the BANG logger
            # This is done for each file.
            # TODO: use a system wide logger if configured
            bangloghandler = logging.FileHandler(filename=logdirectory / 'unpack.log')
            banglogger.addHandler(bangloghandler)
        log(logging.INFO, "Scan %s" % scanuuid)
        log(logging.INFO, "Started scanning %s" % checkfile)

        # create a process manager for managing the threads
        processmanager = multiprocessing.Manager()

        # first create two queues: one for scanning files, the other one
        # for reporting results.
        scanfilequeue = processmanager.JoinableQueue(maxsize=0)
        resultqueue = processmanager.JoinableQueue(maxsize=0)
        processes = []

        # copy the file that needs to be scanned to the temporary
        # directory.
        try:
            shutil.copy(checkfile, unpackdirectory)
        except:
            print("Could not copy %s to scanning directory %s" % (checkfile, unpackdirectory), file=sys.stderr)
            log(logging.WARNING, "Could not copy %s to scanning directory" % checkfile)
            log(logging.INFO, "Finished scanning %s" % checkfile)
            # move the file "STARTED" to "FINISHED" to easily identify
            # active (or crashed) scans
            shutil.move(scandirectory / "STARTED",
                        scandirectory / "FINISHED")
            os.utime(scandirectory / "FINISHED")

            if options.removescandirectory:
                shutil.rmtree(scandirectory)
            continue

        # The scan queue will be used to put files into that need to be
        # scanned and processes. New files wil keep being added to it
        # while results are being unpacked recursively.
        # Initially one file will be in this queue, namely the first file.
        # After files are unpacked they will be added to the queue, as they
        # can be scanned in a trivially parallel way.

        # Create a list of labels to pass around. The first element is
        # tagged as 'root', as it is the root of the unpacking tree.
        labels = ['root']

        # Create a scanjob for the first file to be scanned
        fileresult = FileResult(
                None,
                pathlib.Path(os.path.basename(checkfile)),
                set(labels))
        j = ScanJob(fileresult)
        scanfilequeue.put(j)

        # create a lock to control access to any shared data structures
        processlock = multiprocessing.Lock()

        # create a shared dictionary
        checksumdict = processmanager.dict()

        # create a scan environment for the new scan
        scanenvironment = ScanEnvironment(
            # set the maximum size for the amount of bytes to be read
            maxbytes = maxbytes,
            # set the size of bytes to be read during scanning hashes
            readsize = 10240,
            createbytecounter = options.createbytecounter,
            createjson = options.createjson,
            tlshmaximum = options.tlshmaximum,
            synthesizedminimum = 10,
            logging = banglogging.uselogging,
            paddingname = 'PADDING',
            unpackdirectory = unpackdirectory,
            temporarydirectory = options.temporarydirectory,
            resultsdirectory = resultsdirectory,
            scanfilequeue = scanfilequeue,
            resultqueue = resultqueue,
            processlock = processlock,
            checksumdict = checksumdict,
            )
        scanenvironment.set_unpackparsers(unpackers)

        # create processes for unpacking archives
        for i in range(0, options.bangthreads):
            process = multiprocessing.Process(
                target=processfile,
                args=(scanenvironment,))
            processes.append(process)

        # then start all the processes
        for process in processes:
            process.start()

        # wait for the queues to be empty.
        scanfilequeue.join()

        # There is one result for each file in the result
        # queue, which need to be merged into a structure
        # matching the directory tree that was unpacked. The name
        # of each file that is unpacked serves as key into
        # the structure.
        scantree = {}

        while True:
            try:
                fileresult = resultqueue.get_nowait()
                try:
                    scantree[str(fileresult.filename)] = fileresult.get()
                    resultqueue.task_done()
                except KeyError:
                    # TODO: this is never the case, is it?
                    pass

            except queue.Empty:
                # Queue is empty
                break

        resultqueue.join()

        # Done processing, terminate processes that were created
        for process in processes:
            process.terminate()

        scandatefinished = datetime.datetime.utcnow()

        # move the file "STARTED" to "FINISHED" to easily identify
        # active (or crashed) scans
        shutil.move(scandirectory / "STARTED",
                    scandirectory / "FINISHED")
        os.utime(scandirectory / "FINISHED")

        # information about the platform
        platform_info = {'machine': platform.machine(),
                         'architecture': platform.architecture()[0],
                         'processor': platform.processor(),
                         'node': platform.node(),
                         'system': platform.system(),
                         'release': platform.release(),
                         'libc': platform.libc_ver()[0],
                         'libcversion': platform.libc_ver()[1],
                        }

        # some information about the used Python version
        python_info = {'version': platform.python_version(),
                       'implementation': platform.python_implementation(),
                      }

        # now store the scan tree results with other data
        scanresult = {
            'scantree': scantree,
            # statistics about this particular session
            'session': {'start': scandate,
                        'stop': scandatefinished,
                        'duration': (scandatefinished - scandate).total_seconds(),
                        # 'user': getpass.getuser(),
                        'uid': os.getuid(),
                        'checkfile': checkfile,
                        'uuid': scanuuid,
                        'platform': platform_info,
                        'python': python_info,
                       }
        }

        # write all results to a Python pickle
        picklefile = open(scandirectory / 'bang.pickle', 'wb')
        PickleReporter(scanenvironment).top_level_report(scanresult, picklefile)
        picklefile.close()

        # optionally write the same data in JSON format
        if options.createjson:
            jsonfile = open(scandirectory / 'bang.json', 'w')
            JsonReporter(jsonfile).report(scanresult)
            jsonfile.close()

        # optionally create a human readable report of the scan results
        if options.writereport:
            reportfile = open(scandirectory / 'report.txt', 'w')
            HumanReadableReporter(reportfile).report(scanresult)
            reportfile.close()

        log(logging.INFO, "Finished scanning %s" % checkfile)

        if options.uselogging:
            # flush any remaining data to the log file
            bangloghandler.flush()

            # remove the log file from the system logger
            banglogger.removeHandler(bangloghandler)
            bangloghandler.close()

        # optionally remove the unpack directory
        if options.removescandata:
            shutil.rmtree(unpackdirectory)

        # optionally remove the entire scan directory
        if options.removescandirectory:
            shutil.rmtree(scandirectory)

    # finally shut down logging
    logging.shutdown()


if __name__ == "__main__":
    main(sys.argv)
